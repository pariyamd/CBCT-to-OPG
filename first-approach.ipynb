{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBCT to OPG\n",
    "### This notebook is a representation of steps described in this [link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5594999/) for 2d visualization of a cbct scan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start by installing libraries and importing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install itkwidgets\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "from itkwidgets import view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pydicom library to read every slice of image stored in a directory.\n",
    "Ensure that all slices do have slicelocation attribute and are of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file count: 420\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "path = '/home/pariya/S0000001119/'\n",
    "for s in os.listdir(path):\n",
    "#     print(\"loading {}\".format(s))\n",
    "    files.append(pydicom.dcmread(path + s))\n",
    "print(\"file count: {}\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped 0 slices\n"
     ]
    }
   ],
   "source": [
    "# skip files with no SliceLocation\n",
    "slices = []\n",
    "skipcount = 0\n",
    "for f in files:\n",
    "    if hasattr(f, 'SliceLocation'):\n",
    "        slices.append(f)\n",
    "    else:\n",
    "        skipcount = skipcount + 1\n",
    "\n",
    "print(\"skipped {} slices\".format(skipcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = slices[0].pixel_array.shape\n",
    "removed=[]\n",
    "#ensure all slices are the same size\n",
    "for s in slices:\n",
    "    if sh!=s.pixel_array.shape:\n",
    "        removed.append(s)\n",
    "\n",
    "#remove slices with different shape\n",
    "for r in removed:\n",
    "    slices.remove(r)\n",
    "    \n",
    "# sort them is correct order\n",
    "slices = sorted(slices, key=lambda s: s.SliceLocation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack up all the 2D arrays of slices to costruct a 3D array and visualize it using itkwidget.\n",
    "take a good look at the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1838078d94ff4a16bad43bfa02e9e9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(rendered_image=<itk.itkImagePython.itkImageD3; proxy of <Swig Object of type 'itkImageD3 *' at 0x7fee91â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create 3D array\n",
    "img_shape = list(sh)\n",
    "img_shape.append(len(slices))\n",
    "img3d = np.zeros(img_shape)\n",
    "m=0\n",
    "\n",
    "# fill 3D array with every 2D slice\n",
    "for i, s in enumerate(slices):\n",
    "    if s.pixel_array.shape != slices[0].pixel_array.shape:\n",
    "        continue\n",
    "    img2d = s.pixel_array\n",
    "    img3d[:, :, i] = img2d\n",
    "\n",
    "# 3D visualization of data\n",
    "view(img3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intensity normalization\n",
    "\n",
    "In order to find the threshhold first we visualize the intesity histogram, then fit a gaussian distribute to the histogram finally we get mean and standard deviation of data intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intensity normalization\n",
    "def intensity_normalization(img):\n",
    "    minimum = np.min(img)\n",
    "    maximum = np.max(img)\n",
    "    print(minimum,maximum)\n",
    "    img = (img-minimum)/(maximum-minimum)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 65508.0\n"
     ]
    }
   ],
   "source": [
    "img3d=intensity_normalization(img3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = 34050472.677  mu = 0.009  sigma = 0.031 k = -60193.788 $\n"
     ]
    }
   ],
   "source": [
    "#intensity histogtram\n",
    "from pylab import *\n",
    "from scipy.optimize import leastsq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0,1,101)\n",
    "oneD_array=np.array(img3d.flatten())\n",
    "n,bins,patches = plt.hist(oneD_array,x)\n",
    "\n",
    "fitfunc  = lambda p, x: p[0]*exp(-0.5*((x-p[1])/p[2])**2)+p[3]\n",
    "errfunc  = lambda p, x, y: (y - fitfunc(p, x))\n",
    "\n",
    "\n",
    "init  = [1.0, 0.5, 0.5, 0.5]\n",
    "out   = leastsq( errfunc, init, args=(x[:-1], n))\n",
    "c = out[0]\n",
    "# print (c[0],c[1],abs(c[2]),c[3])\n",
    "plot(x[:-1], fitfunc(c,x[:-1] ))\n",
    "print(r'A = %.3f  mu = %.3f  sigma = %.3f k = %.3f $' %(c[0],c[1],abs(c[2]),c[3]));\n",
    "\n",
    "mu=c[1]\n",
    "sigma=abs(c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Thresholding\n",
    "based on the paper we are going to use a linear combination of mean and standard deviation to determine threshold value.\n",
    "\n",
    "In the paper it is proposed to find the slice that best represents patients dental arch to find template polynomial, but in this data i projected every slice on a 2d plane and summed up every slice to make a better representation of patients dental arc (due to missing tooth and imaging error), which led to choosing a larger value for w which is standard deviation's coeficient so before projecting all the slices filtering is done better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Thresholding\n",
    "T = mu +3.8*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "img=deepcopy(img3d)\n",
    "img[img3d>T]=1\n",
    "img[img3d<T]=0\n",
    "#add slices 200 and the rest by second axis\n",
    "img_proj=np.sum(img[:,:,200:335],axis=2)\n",
    "img_proj[img_proj>0]=1\n",
    "\n",
    "#comparison\n",
    "TP=mu+3*sigma\n",
    "img_p=deepcopy(img3d)\n",
    "img_p[img3d>TP]=1\n",
    "img_p[img3d<TP]=0\n",
    "\n",
    "fig,axs=plt.subplots(1,2,figsize=(10,5))\n",
    "axs[1].imshow(img_proj)\n",
    "axs[1].set_title(\"projected arc\")\n",
    "axs[0].imshow(img_p[:,:,300])\n",
    "axs[0].set_title(\"slice 300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(original, filtered, filter_name):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6), sharex=True,\n",
    "                                   sharey=True)\n",
    "    ax1.imshow(original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('original')\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(filter_name)\n",
    "    ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Morphological operations (hole filling, closing, thinning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker_image(original):\n",
    "    #produce marker image\n",
    "    selem = morphology.square(2)\n",
    "    eroded = morphology.erosion(original, selem)\n",
    "    dilated = morphology.dilation(original, selem)\n",
    "    marker=dilated-eroded\n",
    "    plot_comparison(original,marker , 'marker')\n",
    "    return marker\n",
    "\n",
    "def hole_filling(original):\n",
    "#   #iterative hole-filling\n",
    "#     ic=np.logical_not(original)\n",
    "#     intersect=deepcopy(original)\n",
    "#     for i in range(200):\n",
    "#         selem = morphology.square(5)\n",
    "#         dilated = morphology.dilation(intersect, selem)\n",
    "#         intersect=np.logical_and(dilated,ic)\n",
    "# #     hole_filled=np.logical_not(intersect)\n",
    "#         plot_comparison(original,intersect,\"filled\")\n",
    "    intersect=morphology.flood_fill(original,(100,100),5)\n",
    "    hole_filled=np.logical_not(intersect)\n",
    "    plot_comparison(original,hole_filled,\"flood fill\")\n",
    "    return hole_filled\n",
    "\n",
    "def closing(original):\n",
    "    # morphological closing\n",
    "    selem = morphology.disk(35)\n",
    "    closed=morphology.closing(original,selem)\n",
    "    plot_comparison(original,closed,'closing')\n",
    "    return closed\n",
    "\n",
    "def thinning(original):\n",
    "    #morphological thinning\n",
    "    skeleton=morphology.thin(original==1)\n",
    "    plot_comparison(original,skeleton,\"thinning\")\n",
    "    return skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphology_procces(original):\n",
    "    marker=marker_image(original)\n",
    "    filled=hole_filling(marker)\n",
    "    closed=closing(filled)\n",
    "    thinned=thinning(closed)\n",
    "    return thinned\n",
    "skeleton=morphology_procces(img_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Curve Fitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted_curve():\n",
    "    \n",
    "    xn,yn=np.nonzero(np.rot90(skeleton))\n",
    "    h ,w=skeleton.shape\n",
    "    xn=w-xn\n",
    "    coefs = np.poly1d(np.polyfit(xn, yn,2))\n",
    "    xx = np.arange(0, w).astype(np.int)\n",
    "    yy = np.polyval(coefs, xx)\n",
    "\n",
    "    xx = xx[np.min(xn)-50:np.max(xn)+50]\n",
    "    yy = yy[np.min(xn)-50:np.max(xn)+50]\n",
    "    xx = xx[(0 <= yy) & (yy < h)]\n",
    "    yy = yy[(0 <= yy) & (yy < h)].astype(np.int) \n",
    "\n",
    "    \n",
    "    \n",
    "    fig,axs=plt.subplots(1,3,figsize=(12,4))\n",
    "    plt.ylim(0,640)\n",
    "    plt.xlim(0,640)\n",
    "    axs[0].plot(xn,yn,'.')\n",
    "    axs[0].set_ylim(0,640)\n",
    "    axs[0].set_xlim(0,640)\n",
    "    axs[1].set_ylim(0,640)\n",
    "    axs[1].set_xlim(0,640)\n",
    "    axs[2].set_ylim(0,640)\n",
    "    axs[2].set_xlim(0,640)\n",
    "    axs[0].set_title(\"projected\")\n",
    "    axs[1].set_title('poly 2')\n",
    "    axs[1].plot(xn,yn,'.',xx,yy,'.')\n",
    "    axs[2].imshow(img_proj)\n",
    "    axs[2].plot(xx,yy,'.')\n",
    "    axs[2].set_title('with image')\n",
    "\n",
    "    plt.show()\n",
    "    return (xx,yy,coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,coefs=plot_fitted_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "opg=[]\n",
    "w,h,d=img3d.shape\n",
    "\n",
    "for i in range(100,d):\n",
    "    im=[]\n",
    "    for j in range(len(x)):\n",
    "        im.append(img3d[:,:,i][y[j]][x[j]])\n",
    "    opg.append(im)\n",
    "plt.imshow(opg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
